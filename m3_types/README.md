# Types
## Types, energy usage and inference, quantization, sparsity and pruning of neural networks

* Floats
* Float precision
* Integers
* Energy usage (Vivienne Sze and the controversial paper)
* Inference
* Quantization
* Sparsity
* Pruning
* *-Fast inverse square root
* *-Bit tricks
* *-Basic compression
* *-Batch based data processing
* *-Tensor Cores
* *-Using integers instead of strings in hash tables

## *-Exercise

Find a suitable model and inference library.  
Perform inference.  
Optimize the model and inference process.  
Can you do inferencing on one thread,  
training on another and swap in the new model?  
ADD SUGGESTED MODELS  

## *S-Group discussion and presentation
Pick one of the following topics.  
Read and understand it, then present and discuss the topic with one or more other people.  
Preferably classmates.

* Packing bits for atomic operators
* Inverse depth buffers
* Bittricks, packing normals and colors
* Morton codes / Z-order curves, tiling and GPU textures
* Calculating compression precision in a lossy point cloud compression scheme
* DLSS
* Real-Time Texture Decompression and Upsampling
* 2:4 sparsity with Tensor Cores
